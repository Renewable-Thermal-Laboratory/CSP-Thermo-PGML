{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYuMZXny70b-",
        "outputId": "0dc0ef10-8737-4789-bfde-e0c48e46dd5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/Trimmed_TC_updated'\n",
            "/content/drive/MyDrive/Colab Notebooks/Trimmed_TC_updated\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/Colab\\ Notebooks/Trimmed_TC_updated\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yTtoyJA-1_8",
        "outputId": "568af862-2fcc-45e3-b0ef-ac64f7c66789"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " combined_data.csv\n",
            "'h2_flux88_abs0_mr_surf0_571s - Sheet1.csv'\n",
            "'h2_flux88_abs0_surf0_431s - Sheet1.csv'\n",
            "'h2_flux88_abs0_surf0_585s - Sheet2.csv'\n",
            "'h2_flux88_abs0_surf0_probeUp_590s - Sheet2.csv'\n",
            "'h2_flux88_abs0_wr_surf0_368s - Sheet1.csv'\n",
            "'h2_flux88_abs25_newSalt_surf0_172s - Sheet1.csv'\n",
            "'h2_flux88_abs25_newSalt_wr_surf0_123s - Sheet1.csv'\n",
            "'h2_flux88_abs25_surf0_493s - Sheet1.csv'\n",
            "'h2_flux88_abs25_wr_surf0_393s - Sheet1.csv'\n",
            "'h2_flux88_abs25_wr_surfParAdded_169s - Sheet1.csv'\n",
            "'h2_flux88_abs25_wr_surfSimD_525s - Sheet1.csv'\n",
            "'h2_flux88_abs92_surf0_115s - Sheet1.csv'\n",
            "'h2_flux88_abs92_surf0_probeUp_193s - Sheet1.csv'\n",
            "'h2_flux88_abs92_wr_surf0_215s - Sheet1.csv'\n",
            " h3_flux88_abs0_mr_surf0_635s-Sheet1.csv\n",
            " h3_flux88_abs0_surf0_644s-Sheet2.csv\n",
            "'h3_flux88_abs0_surf0_719s - Sheet1.csv'\n",
            " h3_flux88_abs0_surf0_825s-Sheet3.csv\n",
            " h3_flux88_abs0_wr_surf0_416s-Sheet1.csv\n",
            " h3_flux88_abs25_mr_surf0_796s-Sheet1.csv\n",
            " h3_flux88_abs25_surf0_439s-Sheet2.csv\n",
            " h3_flux88_abs25_surf0_660s-Sheet1.csv\n",
            " h3_flux88_abs25_wr_surf0_422s-Sheet1.csv\n",
            " h3_flux88_abs25_wr_surf0_746s-Sheet2.csv\n",
            " h3_flux88_abs90_mr_surf0_506s-Sheet1.csv\n",
            " h3_flux88_abs90_surf0_692s-Sheet2.csv\n",
            " h3_flux88_abs90_surf0_747s-Sheet3.csv\n",
            " h3_flux88_abs90_surf0_749s-Sheet1.csv\n",
            " h3_flux88_abs90_surf0_Redone_640s-Sheet3.csv\n",
            " h3_flux88_abs90_surf0_Redone_again2_398s-Sheet1.csv\n",
            " h3_flux88_abs90_surf0_Redone_again_266s-Sheet1.csv\n",
            " h3_flux88_abs90_surf0_Redone_again3_344s-Sheet1.csv\n",
            " h3_flux88_abs90_wr_surf0_529s-Sheet1.csv\n",
            "'h6_flux73_abs0_surf0_429s - Sheet2.csv'\n",
            "'h6_flux73_abs0_surf0_511s - Sheet3.csv'\n",
            "'h6_flux73_abs0_surf0_868s - Sheet1.csv'\n",
            "'h6_flux73_abs0_surf0_newSalt_398s - Sheet1.csv'\n",
            "'h6_flux73_abs0_surf1_660s - Sheet1.csv'\n",
            "'h6_flux73_abs0_surf1_754s - Sheet3.csv'\n",
            "'h6_flux73_abs0_surf1_868s - Sheet2.csv'\n",
            "'h6_flux78_abs0_surf0_450s - Sheet3.csv'\n",
            "'h6_flux78_abs0_surf0_523s - Sheet2.csv'\n",
            "'h6_flux78_abs0_surf0_745s - Sheet1.csv'\n",
            "'h6_flux78_abs0_surf0_newSalt_641s - Sheet1.csv'\n",
            "'h6_flux78_abs0_surf1_newSalt_466s - Sheet1.csv'\n",
            "'h6_flux78_abs0_surf1_newSalt_505s - Sheet3.csv'\n",
            "'h6_flux78_abs0_surf1_newSalt_851s - Sheet2.csv'\n",
            "'h6_flux88_abs0_graphDisc_surf0_759s - Sheet1.csv'\n",
            "'h6_flux88_abs0_mr_surf0_617s - Sheet1.csv'\n",
            "'h6_flux88_abs0_surf0_389s - Sheet4.csv'\n",
            "'h6_flux88_abs0_surf0_689s - Sheet3.csv'\n",
            "'h6_flux88_abs0_surf0_800s - Sheet1.csv'\n",
            "'h6_flux88_abs0_surf0_800s - Sheet2.csv'\n",
            "'h6_flux88_abs0_surf0_longRun_558s - Sheet2.csv'\n",
            "'h6_flux88_abs0_surf0_longRun_643s - Sheet3.csv'\n",
            "'h6_flux88_abs0_surf0_longRun_762s - Sheet1.csv'\n",
            "'h6_flux88_abs0_surf1_491s - Sheet3.csv'\n",
            "'h6_flux88_abs0_surf1_545s - Sheet2.csv'\n",
            "'h6_flux88_abs0_surf1_790s - Sheet1.csv'\n",
            "'h6_flux88_abs0_surf1_newSalt_573s - Sheet2.csv'\n",
            "'h6_flux88_abs0_surf1_newSalt_689s - Sheet1.csv'\n",
            "'h6_flux88_abs0_wr_surf0_632s - Sheet1.csv'\n",
            "'h6_flux88_abs20_mr_surf0_537s - Sheet1.csv'\n",
            "'h6_flux88_abs20_surf0_389s - Sheet3.csv'\n",
            "'h6_flux88_abs20_surf0_651s - Sheet4.csv'\n",
            "'h6_flux88_abs20_surf0_699s - Sheet1.csv'\n",
            "'h6_flux88_abs20_surf0_781s - Sheet2.csv'\n",
            "'h6_flux88_abs20_surf0_longRun_612s - Sheet2.csv'\n",
            "'h6_flux88_abs20_surf0_longRun_780s - Sheet1.csv'\n",
            "'h6_flux88_abs20_surf1_613s - Sheet1.csv'\n",
            "'h6_flux88_abs20_surf1_675s - Sheet3.csv'\n",
            "'h6_flux88_abs20_surf1_830s - Sheet2.csv'\n",
            "'h6_flux88_abs20_wr_surf0_734s - Sheet1.csv'\n",
            "'h6_flux88_abs92_mr_surf0_580s - Sheet1.csv'\n",
            "'h6_flux88_abs92_surf0_598s - Sheet1.csv'\n",
            "'h6_flux88_abs92_surf0_628s - Sheet4.csv'\n",
            "'h6_flux88_abs92_surf0_630s - Sheet2.csv'\n",
            "'h6_flux88_abs92_surf0_648s - Sheet3.csv'\n",
            "'h6_flux88_abs92_surf0_longRun_618s - Sheet1.csv'\n",
            "'h6_flux88_abs92_surf0_longRun_647s - Sheet2.csv'\n",
            "'h6_flux88_abs92_wr_surf0_835s - Sheet1.csv'\n",
            " thermal_model_weights.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "rP-VCBDo9H-G"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining All Data Files into One"
      ],
      "metadata": {
        "id": "I3T5Zu9hrZTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "pattern = r\"h(\\d+)_flux(\\d+)_abs(\\d+).*?_surf(\\d+).*?_(\\d+)s\"\n",
        "\n",
        "# % mapping tables for quick lookup\n",
        "h_map = {2:0.0375, 3:0.084, 6:0.1575}\n",
        "flux_map = {88: 25900, 78: 21250, 73: 19400}\n",
        "abs_val_map = {0: 3, 92: 100}\n",
        "surf_map = {0:0.98, 1:0.76}\n",
        "\n",
        "dataframes = []\n",
        "for filename in os.listdir(\"./\"):\n",
        "    if filename.endswith(\".csv\"):\n",
        "\n",
        "        match = re.search(pattern, filename)\n",
        "        if match:\n",
        "            h = int(match.group(1))\n",
        "            flux = int(match.group(2))\n",
        "            abs_val = int(match.group(3))\n",
        "            surf = int(match.group(4))\n",
        "            min_time = int(match.group(5))\n",
        "\n",
        "            # flux from 73 → 19.4, 88 → 25.9\n",
        "            if h in h_map:\n",
        "              h = h_map[h]\n",
        "            if flux in flux_map:\n",
        "              flux = flux_map[flux]\n",
        "\n",
        "            if abs_val in abs_val_map:\n",
        "              abs_val = abs_val_map[abs_val]\n",
        "\n",
        "            if surf in surf_map:\n",
        "              surf = surf_map[surf]\n",
        "\n",
        "\n",
        "\n",
        "            print(filename)\n",
        "            file_path = os.path.join(\"\", filename)\n",
        "            print(file_path)\n",
        "            data = pd.read_csv(file_path, encoding=\"utf-8-sig\")  # UTF-8 with BOM\n",
        "\n",
        "            if 'Time' in data.columns:\n",
        "                data = data[data['Time'] >= min_time].copy()\n",
        "\n",
        "            data[\"h\"] = h\n",
        "            data[\"flux\"] = flux\n",
        "            data[\"abs\"] = abs_val\n",
        "            data[\"surf\"] = surf\n",
        "\n",
        "            dataframes.append(data)\n",
        "\n",
        "# Combine all dataframes into one\n",
        "combined_data = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "print(combined_data.head())\n",
        "\n",
        "combined_data.to_csv(\"combined_data.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg4-pTVqS1_x",
        "outputId": "f4259b23-da06-471c-a36f-aa3b245486f9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h6_flux88_abs20_wr_surf0_734s - Sheet1.csv\n",
            "h6_flux88_abs20_wr_surf0_734s - Sheet1.csv\n",
            "h2_flux88_abs25_surf0_493s - Sheet1.csv\n",
            "h2_flux88_abs25_surf0_493s - Sheet1.csv\n",
            "h6_flux78_abs0_surf0_newSalt_641s - Sheet1.csv\n",
            "h6_flux78_abs0_surf0_newSalt_641s - Sheet1.csv\n",
            "h6_flux88_abs0_surf1_newSalt_573s - Sheet2.csv\n",
            "h6_flux88_abs0_surf1_newSalt_573s - Sheet2.csv\n",
            "h2_flux88_abs92_surf0_115s - Sheet1.csv\n",
            "h2_flux88_abs92_surf0_115s - Sheet1.csv\n",
            "h6_flux88_abs20_surf1_675s - Sheet3.csv\n",
            "h6_flux88_abs20_surf1_675s - Sheet3.csv\n",
            "h6_flux88_abs0_surf1_790s - Sheet1.csv\n",
            "h6_flux88_abs0_surf1_790s - Sheet1.csv\n",
            "h6_flux88_abs92_surf0_longRun_647s - Sheet2.csv\n",
            "h6_flux88_abs92_surf0_longRun_647s - Sheet2.csv\n",
            "h2_flux88_abs0_surf0_431s - Sheet1.csv\n",
            "h2_flux88_abs0_surf0_431s - Sheet1.csv\n",
            "h6_flux88_abs20_surf0_781s - Sheet2.csv\n",
            "h6_flux88_abs20_surf0_781s - Sheet2.csv\n",
            "h6_flux73_abs0_surf1_660s - Sheet1.csv\n",
            "h6_flux73_abs0_surf1_660s - Sheet1.csv\n",
            "h6_flux88_abs20_surf1_830s - Sheet2.csv\n",
            "h6_flux88_abs20_surf1_830s - Sheet2.csv\n",
            "h6_flux88_abs92_surf0_598s - Sheet1.csv\n",
            "h6_flux88_abs92_surf0_598s - Sheet1.csv\n",
            "h2_flux88_abs0_surf0_585s - Sheet2.csv\n",
            "h2_flux88_abs0_surf0_585s - Sheet2.csv\n",
            "h6_flux88_abs0_surf1_545s - Sheet2.csv\n",
            "h6_flux88_abs0_surf1_545s - Sheet2.csv\n",
            "h6_flux73_abs0_surf1_754s - Sheet3.csv\n",
            "h6_flux73_abs0_surf1_754s - Sheet3.csv\n",
            "h6_flux88_abs0_surf0_800s - Sheet1.csv\n",
            "h6_flux88_abs0_surf0_800s - Sheet1.csv\n",
            "h6_flux73_abs0_surf0_429s - Sheet2.csv\n",
            "h6_flux73_abs0_surf0_429s - Sheet2.csv\n",
            "h6_flux78_abs0_surf1_newSalt_505s - Sheet3.csv\n",
            "h6_flux78_abs0_surf1_newSalt_505s - Sheet3.csv\n",
            "h2_flux88_abs0_wr_surf0_368s - Sheet1.csv\n",
            "h2_flux88_abs0_wr_surf0_368s - Sheet1.csv\n",
            "h6_flux88_abs20_mr_surf0_537s - Sheet1.csv\n",
            "h6_flux88_abs20_mr_surf0_537s - Sheet1.csv\n",
            "h6_flux88_abs0_mr_surf0_617s - Sheet1.csv\n",
            "h6_flux88_abs0_mr_surf0_617s - Sheet1.csv\n",
            "h6_flux88_abs0_wr_surf0_632s - Sheet1.csv\n",
            "h6_flux88_abs0_wr_surf0_632s - Sheet1.csv\n",
            "h2_flux88_abs25_newSalt_wr_surf0_123s - Sheet1.csv\n",
            "h2_flux88_abs25_newSalt_wr_surf0_123s - Sheet1.csv\n",
            "h6_flux88_abs0_surf1_491s - Sheet3.csv\n",
            "h6_flux88_abs0_surf1_491s - Sheet3.csv\n",
            "h6_flux88_abs20_surf0_699s - Sheet1.csv\n",
            "h6_flux88_abs20_surf0_699s - Sheet1.csv\n",
            "h2_flux88_abs92_surf0_probeUp_193s - Sheet1.csv\n",
            "h2_flux88_abs92_surf0_probeUp_193s - Sheet1.csv\n",
            "h6_flux88_abs92_surf0_630s - Sheet2.csv\n",
            "h6_flux88_abs92_surf0_630s - Sheet2.csv\n",
            "h2_flux88_abs25_newSalt_surf0_172s - Sheet1.csv\n",
            "h2_flux88_abs25_newSalt_surf0_172s - Sheet1.csv\n",
            "h6_flux88_abs0_surf0_longRun_762s - Sheet1.csv\n",
            "h6_flux88_abs0_surf0_longRun_762s - Sheet1.csv\n",
            "h6_flux88_abs0_surf0_689s - Sheet3.csv\n",
            "h6_flux88_abs0_surf0_689s - Sheet3.csv\n",
            "h6_flux88_abs92_surf0_longRun_618s - Sheet1.csv\n",
            "h6_flux88_abs92_surf0_longRun_618s - Sheet1.csv\n",
            "h6_flux88_abs0_surf0_longRun_558s - Sheet2.csv\n",
            "h6_flux88_abs0_surf0_longRun_558s - Sheet2.csv\n",
            "h2_flux88_abs0_mr_surf0_571s - Sheet1.csv\n",
            "h2_flux88_abs0_mr_surf0_571s - Sheet1.csv\n",
            "h6_flux78_abs0_surf1_newSalt_851s - Sheet2.csv\n",
            "h6_flux78_abs0_surf1_newSalt_851s - Sheet2.csv\n",
            "h6_flux88_abs20_surf0_longRun_780s - Sheet1.csv\n",
            "h6_flux88_abs20_surf0_longRun_780s - Sheet1.csv\n",
            "h6_flux88_abs0_surf0_longRun_643s - Sheet3.csv\n",
            "h6_flux88_abs0_surf0_longRun_643s - Sheet3.csv\n",
            "h6_flux73_abs0_surf0_newSalt_398s - Sheet1.csv\n",
            "h6_flux73_abs0_surf0_newSalt_398s - Sheet1.csv\n",
            "h6_flux88_abs20_surf0_389s - Sheet3.csv\n",
            "h6_flux88_abs20_surf0_389s - Sheet3.csv\n",
            "h6_flux78_abs0_surf0_450s - Sheet3.csv\n",
            "h6_flux78_abs0_surf0_450s - Sheet3.csv\n",
            "h6_flux73_abs0_surf0_868s - Sheet1.csv\n",
            "h6_flux73_abs0_surf0_868s - Sheet1.csv\n",
            "h6_flux88_abs0_graphDisc_surf0_759s - Sheet1.csv\n",
            "h6_flux88_abs0_graphDisc_surf0_759s - Sheet1.csv\n",
            "h6_flux73_abs0_surf1_868s - Sheet2.csv\n",
            "h6_flux73_abs0_surf1_868s - Sheet2.csv\n",
            "h6_flux78_abs0_surf0_523s - Sheet2.csv\n",
            "h6_flux78_abs0_surf0_523s - Sheet2.csv\n",
            "h6_flux88_abs20_surf1_613s - Sheet1.csv\n",
            "h6_flux88_abs20_surf1_613s - Sheet1.csv\n",
            "h2_flux88_abs92_wr_surf0_215s - Sheet1.csv\n",
            "h2_flux88_abs92_wr_surf0_215s - Sheet1.csv\n",
            "h6_flux78_abs0_surf0_745s - Sheet1.csv\n",
            "h6_flux78_abs0_surf0_745s - Sheet1.csv\n",
            "h2_flux88_abs25_wr_surf0_393s - Sheet1.csv\n",
            "h2_flux88_abs25_wr_surf0_393s - Sheet1.csv\n",
            "h6_flux88_abs92_surf0_628s - Sheet4.csv\n",
            "h6_flux88_abs92_surf0_628s - Sheet4.csv\n",
            "h6_flux88_abs0_surf0_389s - Sheet4.csv\n",
            "h6_flux88_abs0_surf0_389s - Sheet4.csv\n",
            "h6_flux73_abs0_surf0_511s - Sheet3.csv\n",
            "h6_flux73_abs0_surf0_511s - Sheet3.csv\n",
            "h6_flux88_abs20_surf0_651s - Sheet4.csv\n",
            "h6_flux88_abs20_surf0_651s - Sheet4.csv\n",
            "h6_flux78_abs0_surf1_newSalt_466s - Sheet1.csv\n",
            "h6_flux78_abs0_surf1_newSalt_466s - Sheet1.csv\n",
            "h6_flux88_abs92_surf0_648s - Sheet3.csv\n",
            "h6_flux88_abs92_surf0_648s - Sheet3.csv\n",
            "h6_flux88_abs20_surf0_longRun_612s - Sheet2.csv\n",
            "h6_flux88_abs20_surf0_longRun_612s - Sheet2.csv\n",
            "h6_flux88_abs0_surf0_800s - Sheet2.csv\n",
            "h6_flux88_abs0_surf0_800s - Sheet2.csv\n",
            "h2_flux88_abs0_surf0_probeUp_590s - Sheet2.csv\n",
            "h2_flux88_abs0_surf0_probeUp_590s - Sheet2.csv\n",
            "h6_flux88_abs92_mr_surf0_580s - Sheet1.csv\n",
            "h6_flux88_abs92_mr_surf0_580s - Sheet1.csv\n",
            "h6_flux88_abs0_surf1_newSalt_689s - Sheet1.csv\n",
            "h6_flux88_abs0_surf1_newSalt_689s - Sheet1.csv\n",
            "h6_flux88_abs92_wr_surf0_835s - Sheet1.csv\n",
            "h6_flux88_abs92_wr_surf0_835s - Sheet1.csv\n",
            "h3_flux88_abs0_surf0_719s - Sheet1.csv\n",
            "h3_flux88_abs0_surf0_719s - Sheet1.csv\n",
            "h3_flux88_abs0_surf0_644s-Sheet2.csv\n",
            "h3_flux88_abs0_surf0_644s-Sheet2.csv\n",
            "h3_flux88_abs0_surf0_825s-Sheet3.csv\n",
            "h3_flux88_abs0_surf0_825s-Sheet3.csv\n",
            "h3_flux88_abs0_mr_surf0_635s-Sheet1.csv\n",
            "h3_flux88_abs0_mr_surf0_635s-Sheet1.csv\n",
            "h3_flux88_abs0_wr_surf0_416s-Sheet1.csv\n",
            "h3_flux88_abs0_wr_surf0_416s-Sheet1.csv\n",
            "h3_flux88_abs25_surf0_660s-Sheet1.csv\n",
            "h3_flux88_abs25_surf0_660s-Sheet1.csv\n",
            "h3_flux88_abs25_surf0_439s-Sheet2.csv\n",
            "h3_flux88_abs25_surf0_439s-Sheet2.csv\n",
            "h3_flux88_abs25_mr_surf0_796s-Sheet1.csv\n",
            "h3_flux88_abs25_mr_surf0_796s-Sheet1.csv\n",
            "h3_flux88_abs90_wr_surf0_529s-Sheet1.csv\n",
            "h3_flux88_abs90_wr_surf0_529s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_749s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_749s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_692s-Sheet2.csv\n",
            "h3_flux88_abs90_surf0_692s-Sheet2.csv\n",
            "h3_flux88_abs90_surf0_747s-Sheet3.csv\n",
            "h3_flux88_abs90_surf0_747s-Sheet3.csv\n",
            "h3_flux88_abs90_mr_surf0_506s-Sheet1.csv\n",
            "h3_flux88_abs90_mr_surf0_506s-Sheet1.csv\n",
            "h3_flux88_abs25_wr_surf0_746s-Sheet2.csv\n",
            "h3_flux88_abs25_wr_surf0_746s-Sheet2.csv\n",
            "h3_flux88_abs25_wr_surf0_422s-Sheet1.csv\n",
            "h3_flux88_abs25_wr_surf0_422s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_Redone_640s-Sheet3.csv\n",
            "h3_flux88_abs90_surf0_Redone_640s-Sheet3.csv\n",
            "h3_flux88_abs90_surf0_Redone_again_266s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_Redone_again_266s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_Redone_again2_398s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_Redone_again2_398s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_Redone_again3_344s-Sheet1.csv\n",
            "h3_flux88_abs90_surf0_Redone_again3_344s-Sheet1.csv\n",
            "   Time  TC1_tip     TC2     TC3     TC4     TC5     TC6     TC7     TC8  \\\n",
            "0   734   360.74  360.08  360.53  360.79  360.14  361.79  358.63  359.26   \n",
            "1   735   360.73  360.05  360.45  360.77  360.10  361.77  358.58  359.25   \n",
            "2   736   360.73  360.01  360.37  360.76  360.05  361.74  358.51  359.34   \n",
            "3   737   360.71  359.99  360.33  360.75  360.02  361.73  358.51  359.47   \n",
            "4   738   360.69  359.95  360.32  360.76  360.01  361.73  358.55  359.68   \n",
            "\n",
            "      TC9    TC10       h   flux  abs  surf  TC_9.5  TC_Bottom_rec_groove  \\\n",
            "0  356.22  335.77  0.1575  25900   20  0.98     NaN                   NaN   \n",
            "1  356.10  335.32  0.1575  25900   20  0.98     NaN                   NaN   \n",
            "2  356.20  334.95  0.1575  25900   20  0.98     NaN                   NaN   \n",
            "3  356.41  334.62  0.1575  25900   20  0.98     NaN                   NaN   \n",
            "4  356.62  334.35  0.1575  25900   20  0.98     NaN                   NaN   \n",
            "\n",
            "   TC_wall_ins_ext  TC_bottom_ins_groove  \n",
            "0              NaN                   NaN  \n",
            "1              NaN                   NaN  \n",
            "2              NaN                   NaN  \n",
            "3              NaN                   NaN  \n",
            "4              NaN                   NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# so for this model, the training data will be\n",
        "# h (depth), flux (q0), abs (absorption coefficient k), surf (surface emisisivty epsilon), and varying time (tStep)\n",
        "# and y will be the thermal couples values FOR THAT TIME\n",
        "data = pd.read_csv(\"combined_data.csv\")\n",
        "\n",
        "# removing these two columns, some data files have these, some don't. I'll worry about them later +\n",
        "# need to ask what they do again\n",
        "data.drop(columns=[\"TC_9.5\", \"TC_Bottom_rec_groove\",\"TC_wall_ins_ext\", \"TC_bottom_ins_groove\"], axis=1, inplace=True)\n",
        "\n",
        "# making sure no nulls in  other  rows after r emoving these two\n",
        "print(\"Null Check: \", data.isnull().sum())\n",
        "\n",
        "X = data[[\"Time\", \"h\", \"flux\", \"abs\", \"surf\"]]\n",
        "print(\"INPUTS: \\n\", X.head())\n",
        "y = data.drop(columns=[\"Time\", \"h\", \"flux\", \"abs\", \"surf\"])\n",
        "print(\"OUPUTS: \\n\", y.head())\n",
        "\n",
        "y_columns = y.columns\n",
        "# MinMaxScaler -> normalization, standardize when data is not normal (not in our case)\n",
        "X_scaler = MinMaxScaler()\n",
        "y_scaler = MinMaxScaler()\n",
        "X = X_scaler.fit_transform(X)\n",
        "y = y_scaler.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_size = X_train.shape[1]\n",
        "print(\"input size: \", input_size)\n",
        "\n",
        "output_size = y_train.shape[1]\n",
        "print(\"output size: \", output_size)\n",
        "\n",
        "print(\"Amount of Training Data: \", X_train.shape[0])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oYMf52zCAsSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7a360b-106f-4535-ba1e-31b86cef426b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null Check:  Time       0\n",
            "TC1_tip    0\n",
            "TC2        0\n",
            "TC3        0\n",
            "TC4        0\n",
            "TC5        0\n",
            "TC6        0\n",
            "TC7        0\n",
            "TC8        0\n",
            "TC9        0\n",
            "TC10       0\n",
            "h          0\n",
            "flux       0\n",
            "abs        0\n",
            "surf       0\n",
            "dtype: int64\n",
            "INPUTS: \n",
            "    Time       h   flux  abs  surf\n",
            "0   734  0.1575  25900   20  0.98\n",
            "1   735  0.1575  25900   20  0.98\n",
            "2   736  0.1575  25900   20  0.98\n",
            "3   737  0.1575  25900   20  0.98\n",
            "4   738  0.1575  25900   20  0.98\n",
            "OUPUTS: \n",
            "    TC1_tip     TC2     TC3     TC4     TC5     TC6     TC7     TC8     TC9  \\\n",
            "0   360.74  360.08  360.53  360.79  360.14  361.79  358.63  359.26  356.22   \n",
            "1   360.73  360.05  360.45  360.77  360.10  361.77  358.58  359.25  356.10   \n",
            "2   360.73  360.01  360.37  360.76  360.05  361.74  358.51  359.34  356.20   \n",
            "3   360.71  359.99  360.33  360.75  360.02  361.73  358.51  359.47  356.41   \n",
            "4   360.69  359.95  360.32  360.76  360.01  361.73  358.55  359.68  356.62   \n",
            "\n",
            "     TC10  \n",
            "0  335.77  \n",
            "1  335.32  \n",
            "2  334.95  \n",
            "3  334.62  \n",
            "4  334.35  \n",
            "input size:  5\n",
            "output size:  10\n",
            "Amount of Training Data:  59044\n",
            "Sample inputs (real values):\n",
            "     Time       h     flux  abs  surf\n",
            "0  1049.0  0.1575  25900.0  3.0  0.98\n",
            "1  1081.0  0.1575  25900.0  3.0  0.98\n",
            "2   933.0  0.1575  25900.0  3.0  0.76\n",
            "3  1322.0  0.1575  21250.0  3.0  0.98\n",
            "4  1093.0  0.1575  25900.0  3.0  0.76\n",
            "\n",
            "Sample outputs (real values):\n",
            "      TC1_tip         TC2         TC3         TC4         TC5         TC6  \\\n",
            "0  361.739990  359.350006  362.669983  362.649994  362.480011  364.170013   \n",
            "1  361.509979  359.840027  361.649994  362.029999  361.609985  363.490021   \n",
            "2  365.820007  364.399994  366.559998  367.050018  366.880005  369.010010   \n",
            "3  357.619995  356.170013  358.250000  358.350006  357.899994  359.580017   \n",
            "4  364.019989  361.559998  364.200012  364.380005  364.169983  365.830017   \n",
            "\n",
            "          TC7         TC8         TC9        TC10  \n",
            "0  363.940002  364.639984  362.550018  352.320007  \n",
            "1  362.260010  362.769989  360.700012  352.549988  \n",
            "2  368.240021  369.309998  369.980011  356.559998  \n",
            "3  357.830017  357.750000  354.470001  340.429993  \n",
            "4  365.420013  365.929993  366.140015  354.359985  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basic neural net\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size, output_size)\n",
        "\n",
        "# coommon loss func n optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad() # resetting gradients\n",
        "    outputs = model(X_train)\n",
        "\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "# no more calculating grad descent/back propgation, only forward\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test).numpy()\n",
        "\n",
        "# change back predictions and true values\n",
        "y_pred_real = y_scaler.inverse_transform(y_pred)\n",
        "y_test_real = y_scaler.inverse_transform(y_test.numpy())\n",
        "\n",
        "# get RMSE per output\n",
        "rmse_per_output = np.sqrt(np.mean((y_pred_real - y_test_real)**2, axis=0))\n",
        "rmse_overall = np.mean(rmse_per_output)\n",
        "\n",
        "\n",
        "print(\"\\nRMSE per output (°C):\")\n",
        "for col, rmse in zip(y_columns, rmse_per_output):\n",
        "    print(f\"{col}: {rmse:.3f} °C\")\n",
        "\n",
        "print(f\"\\nAverage RMSE across all outputs: {rmse_overall:.3f} °C\")\n",
        "\n",
        "torch.save(model.state_dict(), \"thermal_model_weights.pth\")\n",
        "print(\"Model weights saved to 'thermal_model_weights.pth'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oofb_qxQvEPP",
        "outputId": "5fdfe80f-4dbb-4212-e7c2-3e17cdb5e8ec"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/500], Loss: 0.04046384245157242\n",
            "Epoch [100/500], Loss: 0.02190983295440674\n",
            "Epoch [150/500], Loss: 0.012881455011665821\n",
            "Epoch [200/500], Loss: 0.009649925865232944\n",
            "Epoch [250/500], Loss: 0.008036956191062927\n",
            "Epoch [300/500], Loss: 0.007689033634960651\n",
            "Epoch [350/500], Loss: 0.007546356879174709\n",
            "Epoch [400/500], Loss: 0.007389561738818884\n",
            "Epoch [450/500], Loss: 0.007201268337666988\n",
            "Epoch [500/500], Loss: 0.007025961298495531\n",
            "\n",
            "RMSE per output (°C):\n",
            "TC1_tip: 32.332 °C\n",
            "TC2: 31.944 °C\n",
            "TC3: 32.295 °C\n",
            "TC4: 31.559 °C\n",
            "TC5: 31.399 °C\n",
            "TC6: 31.322 °C\n",
            "TC7: 31.868 °C\n",
            "TC8: 32.751 °C\n",
            "TC9: 35.395 °C\n",
            "TC10: 37.864 °C\n",
            "\n",
            "Average RMSE across all outputs: 32.873 °C\n",
            "Model weights saved to 'thermal_model_weights.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a Trained Model\n",
        "To use a trained NN, you need the weights as a .pt or .pth file AND the architecture of the NN"
      ],
      "metadata": {
        "id": "170TXBzts9fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "input_size = 5\n",
        "output_size = y.shape[1]\n",
        "model = NeuralNet(input_size, output_size)\n",
        "model.load_state_dict(torch.load('thermal_model_weights.pth')) # load  weights\n",
        "model.eval() # eval mode, no trianing\n"
      ],
      "metadata": {
        "id": "IyxUf5rBpOBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74dd2987-a230-4ecc-e6fc-7af7d2f82e68"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (fc1): Linear(in_features=5, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# time (tStep), h (y), flux (q0), abs (k), surf (epsilon),\n",
        "new_data = [[1049.0, 0.1575, 25900, 3, 0.98]]\n",
        "# still have to scale d ata\n",
        "new_data = X_scaler.transform(new_data)\n",
        "new_data_tensor = torch.tensor(new_data, dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(new_data_tensor)\n",
        "\n",
        "# reverse normalziation to see the acutal outputs\n",
        "predictions = y_scaler.inverse_transform(predictions.numpy())\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "id": "gU2c_fr5pPTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88edf309-9764-48db-9817-2d6c729d5b83"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [[349.1187  348.43625 352.2031  354.99475 353.1865  351.7591  352.80432\n",
            "  350.80362 349.60376 334.27243]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}